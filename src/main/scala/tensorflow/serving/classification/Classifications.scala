// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package tensorflow.serving.classification

/** List of classes for a single item
  * (tensorflow.Example or tensorflow.InferenceExample.features).
  */
@SerialVersionUID(0L)
final case class Classifications(
    classes: _root_.scala.collection.Seq[tensorflow.serving.classification.Class] = _root_.scala.collection.Seq.empty
    ) extends scalapb.GeneratedMessage with scalapb.Message[Classifications] with scalapb.lenses.Updatable[Classifications] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      classes.foreach(classes => __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(classes.serializedSize) + classes.serializedSize)
      __size
    }
    final override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      classes.foreach { __v =>
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__v.serializedSize)
        __v.writeTo(_output__)
      };
    }
    def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): tensorflow.serving.classification.Classifications = {
      val __classes = (_root_.scala.collection.immutable.Vector.newBuilder[tensorflow.serving.classification.Class] ++= this.classes)
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __classes += _root_.scalapb.LiteParser.readMessage(_input__, tensorflow.serving.classification.Class.defaultInstance)
          case tag => _input__.skipField(tag)
        }
      }
      tensorflow.serving.classification.Classifications(
          classes = __classes.result()
      )
    }
    def clearClasses = copy(classes = _root_.scala.collection.Seq.empty)
    def addClasses(__vs: tensorflow.serving.classification.Class*): Classifications = addAllClasses(__vs)
    def addAllClasses(__vs: TraversableOnce[tensorflow.serving.classification.Class]): Classifications = copy(classes = classes ++ __vs)
    def withClasses(__v: _root_.scala.collection.Seq[tensorflow.serving.classification.Class]): Classifications = copy(classes = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => classes
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(classes.map(_.toPMessage)(_root_.scala.collection.breakOut))
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = tensorflow.serving.classification.Classifications
}

object Classifications extends scalapb.GeneratedMessageCompanion[tensorflow.serving.classification.Classifications] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[tensorflow.serving.classification.Classifications] = this
  def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, scala.Any]): tensorflow.serving.classification.Classifications = {
    require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
    val __fields = javaDescriptor.getFields
    tensorflow.serving.classification.Classifications(
      __fieldsMap.getOrElse(__fields.get(0), Nil).asInstanceOf[_root_.scala.collection.Seq[tensorflow.serving.classification.Class]]
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[tensorflow.serving.classification.Classifications] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      tensorflow.serving.classification.Classifications(
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.collection.Seq[tensorflow.serving.classification.Class]]).getOrElse(_root_.scala.collection.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = ClassificationProto.javaDescriptor.getMessageTypes.get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = ClassificationProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = tensorflow.serving.classification.Class
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = tensorflow.serving.classification.Classifications(
  )
  implicit class ClassificationsLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, tensorflow.serving.classification.Classifications]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, tensorflow.serving.classification.Classifications](_l) {
    def classes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.Seq[tensorflow.serving.classification.Class]] = field(_.classes)((c_, f_) => c_.copy(classes = f_))
  }
  final val CLASSES_FIELD_NUMBER = 1
}
